{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-run the following reference as spark ML initial try \n",
    "\n",
    "- Main method \n",
    "    - CF (Collaborative Filtering)\n",
    "        -  from pyspark.mllib.recommendation import ALS\n",
    "            - https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html\n",
    "\n",
    "        - from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "- Credit \n",
    "    - https://github.com/jadianes/spark-movie-lens/blob/master/notebooks/building-recommender.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.5 :: Anaconda, Inc.\n",
      "Sat Mar 17 08:31:01 GMT 2018\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /Users/yennanliu/anaconda3\n",
      "ds_dash                  /Users/yennanliu/anaconda3/envs/ds_dash\n",
      "pyspark_              *  /Users/yennanliu/anaconda3/envs/pyspark_\n",
      "pytorch_                 /Users/yennanliu/anaconda3/envs/pytorch_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref  : Spark context 'sc' not defined\n",
    "# https://stackoverflow.com/questions/30763951/spark-context-sc-not-defined\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.33:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### comment the original commands here ###\\n\\n\\n# download dataset\\n\\n\\ncomplete_dataset_url = \\'http://files.grouplens.org/datasets/movielens/ml-latest.zip\\'\\nsmall_dataset_url = \\'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\\'\\n\\n\\nimport os\\n\\ndatasets_path = os.path.join(\\'..\\', \\'datasets\\')\\n\\ncomplete_dataset_path = os.path.join(datasets_path, \\'ml-latest.zip\\')\\nsmall_dataset_path = os.path.join(datasets_path, \\'ml-latest-small.zip\\')\\n\\n# --- fix here for python 3 --- #\\n# https://stackoverflow.com/questions/17960942/attributeerror-module-object-has-no-attribute-urlretrieve\\n\\n\\nimport urllib.request\\ndata = urllib.request.urlretrieve(\"http://...\")\\n\\nsmall_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\\ncomplete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)\\n\\nimport zipfile\\n\\nwith zipfile.ZipFile(small_dataset_path, \"r\") as z:\\n    z.extractall(datasets_path)\\n\\nwith zipfile.ZipFile(complete_dataset_path, \"r\") as z:\\n    z.extractall(datasets_path)\\n    \\n    \\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "1)  please download the 2 dataset manually  :\n",
    "\n",
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "\n",
    "2) and save them under :\n",
    "\n",
    "/Users/yennanliu/movie_recommendation/datasets\n",
    "\n",
    "\n",
    "3) then the dataset are here in this spark notebook demo case :\n",
    "\n",
    "yennanliu@yennanliude-MacBook-Pro:~/movie_recommendation/datasets$ ls\n",
    "ml-latest/       ml-latest-small/\n",
    "yennanliu@yennanliude-MacBook-Pro:~/movie_recommendation/datasets$ \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### comment the original commands here ###\n",
    "\n",
    "\n",
    "# download dataset\n",
    "\n",
    "\n",
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "datasets_path = os.path.join('..', 'datasets')\n",
    "\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')\n",
    "\n",
    "# --- fix here for python 3 --- #\n",
    "# https://stackoverflow.com/questions/17960942/attributeerror-module-object-has-no-attribute-urlretrieve\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "data = urllib.request.urlretrieve(\"http://...\")\n",
    "\n",
    "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "    \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- modify here for user customize case --- # \n",
    "\n",
    "datasets_path = '/Users/yennanliu/movie_recommendation/datasets/'\n",
    "\n",
    "\n",
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '31', '2.5'), ('1', '1029', '3.0'), ('1', '1061', '3.0')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
    "    \n",
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2])\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one two'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} {}'.format('one', 'two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9484775108284476\n",
      "For rank 8 the RMSE is 0.9542958228942111\n",
      "For rank 12 the RMSE is 0.9496177208626555\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 30\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    # --- fix here for python 3 --- #\n",
    "    print ('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "# --- fix here for python 3 --- #\n",
    "print ('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((265, 1084), 4.005518221252069),\n",
       " ((605, 1084), 2.8782891719277015),\n",
       " ((561, 1084), 3.2950294269434384)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((563, 44191), (4.0, 4.189270123281259)),\n",
       " ((452, 8860), (2.0, 2.2496701491864757)),\n",
       " ((153, 3825), (3.0, 3.352375845806924))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9400121188663132\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26024289 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "# Load the complete dataset file\n",
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "\n",
    "    \n",
    "    \n",
    "print (\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=30)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8312223761867484\n"
     ]
    }
   ],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45843 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,9), # Star Wars (1977)\n",
    "     (0,1,8), # Toy Story (1995)\n",
    "     (0,16,7), # Casino (1995)\n",
    "     (0,25,8), # Leaving Las Vegas (1995)\n",
    "     (0,32,9), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "     (0,335,4), # Flintstones, The (1994)\n",
    "     (0,379,3), # Timecop (1994)\n",
    "     (0,296,7), # Pulp Fiction (1994)\n",
    "     (0,858,10) , # Godfather, The (1972)\n",
    "     (0,50,8) # Usual Suspects, The (1995)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: %s' % new_user_ratings_RDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 186.852 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in %s seconds\" % round(tt,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(110593,\n",
       "  ((6.395908451737249, \"Full House (O. Henry's Full House) (1952)\"), 9)),\n",
       " (104451,\n",
       "  ((4.833250006473915,\n",
       "    'Dealing: Or the Berkeley-to-Boston Forty-Brick Lost-Bag Blues (1972)'),\n",
       "   1)),\n",
       " (174085, ((6.924064511855505, 'Fast and Furry-Ous (1949)'), 5))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies (with more than 25 reviews):\n",
      "('Baseball (1994)', 9.100399853199661, 29)\n",
      "('\"I', 9.019731089887813, 63)\n",
      "('Rabbit Fire (1951)', 8.92529408787243, 35)\n",
      "('\"Human Condition III', 8.81692817401003, 82)\n",
      "('Duck Amuck (1953)', 8.761438822704264, 178)\n",
      "('\"Lonely Wife', 8.727803203868483, 31)\n",
      "('Harakiri (Seppuku) (1962)', 8.717197500135654, 610)\n",
      "('Death on the Staircase (Soupçons) (2004)', 8.71268283064947, 95)\n",
      "('\"Godfather', 8.687634559928256, 57070)\n",
      "('Neighbours (1952)', 8.660087410228272, 29)\n",
      "('The War (2007)', 8.653926817024384, 44)\n",
      "('Connections (1978)', 8.63871972566877, 48)\n",
      "('Winning Time: Reggie Miller vs. The New York Knicks (2010)', 8.62670619667903, 43)\n",
      "('Dimensions of Dialogue (Moznosti dialogu) (1982)', 8.616723677287581, 51)\n",
      "('Crooks in Clover (a.k.a. Monsieur Gangster) (Les tontons flingueurs) (1963)', 8.61465746889479, 46)\n",
      "('\"Civil War', 8.602210613372119, 400)\n",
      "('Planet Earth (2006)', 8.600185461809389, 754)\n",
      "('\"Life of Oharu', 8.598195047107168, 44)\n",
      "('\"Century of the Self', 8.590715661250826, 175)\n",
      "('One Froggy Evening (1955)', 8.586948782721095, 43)\n",
      "('Seven Samurai (Shichinin no samurai) (1954)', 8.562988687142251, 13994)\n",
      "('Death by Hanging (Koshikei) (1968)', 8.558358992225067, 31)\n",
      "('\"Godfather: Part II', 8.53239436063501, 36679)\n",
      "('The Price of Gold (2014)', 8.524424640734779, 25)\n",
      "('Make Way for Tomorrow (1937)', 8.511685803430112, 102)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=116688, rating=1.9833942568488254)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "model_path = os.path.join('..', 'models', 'movie_lens_als')\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of  the re-run spark demo "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pyspark_)",
   "language": "python",
   "name": "conda_pyspark_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
